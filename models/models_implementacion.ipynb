{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a60139a0",
   "metadata": {},
   "source": [
    "# Laboratorio 1 – Detección de Phishing\n",
    "## Parte 2: Implementación de Modelos de Machine Learning\n",
    "\n",
    "**Universidad del Valle de Guatemala**  \n",
    "**CC3094 – Security Data Science | Semestre I - 2026**  \n",
    "**Autores:** Fabiola Contreras (22787), María José Villafuerte (22129)  \n",
    "**Docente:** Jorge Yass | **Sección:** 11\n",
    "\n",
    "---\n",
    "\n",
    "Este notebook implementa dos modelos de clasificación (**Random Forest** y **Logistic Regression**) para detectar URLs de phishing, utilizando las 7 características seleccionadas en la fase de ingeniería de características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801147b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Librerías importadas correctamente\n"
     ]
    }
   ],
   "source": [
    "# 0. Importación de librerías\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, precision_score, recall_score,\n",
    "    f1_score, accuracy_score, roc_curve, auc\n",
    ")\n",
    "\n",
    "# Configuración de visualización\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "sns.set_style(\"whitegrid\")\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Librerías importadas correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc68b7a",
   "metadata": {},
   "source": [
    "## 1. Carga y Preparación del Dataset\n",
    "\n",
    "Se carga el dataset preprocesado (normalizado con StandardScaler) y se filtran las **7 características seleccionadas**:\n",
    "\n",
    "| Característica | Justificación |\n",
    "|---|---|\n",
    "| `shannon_entropy` | Mide la aleatoriedad de caracteres en la URL; phishing presenta mayor entropía |\n",
    "| `digit_ratio` | Proporción de dígitos; URLs con muchos números son sospechosas |\n",
    "| `sensitive_words` | Presencia de palabras como \"login\", \"verify\", \"account\" |\n",
    "| `url_length` | Longitud total; phishing tiende a usar URLs más largas para ocultar el dominio real |\n",
    "| `domain_length` | Longitud del dominio; dominios falsos suelen ser más largos |\n",
    "| `num_params` | Cantidad de parámetros en query string; URLs complejas son sospechosas |\n",
    "| `special_chars` | Conteo de caracteres especiales no alfanuméricos |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158e3171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cargado desde: ../feature engineering/dataset_phishing_preprocessed.csv\n",
      "\n",
      "Dimensiones del dataset: (11430, 8)\n",
      "\n",
      "Distribución de clases:\n",
      "   Legítimas (0): 5715\n",
      "   Phishing  (1): 5715\n",
      "\n",
      "Primeras 5 observaciones:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shannon_entropy</th>\n",
       "      <th>digit_ratio</th>\n",
       "      <th>sensitive_words</th>\n",
       "      <th>url_length</th>\n",
       "      <th>domain_length</th>\n",
       "      <th>num_params</th>\n",
       "      <th>special_chars</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.132160</td>\n",
       "      <td>-0.594666</td>\n",
       "      <td>-0.341452</td>\n",
       "      <td>-0.436245</td>\n",
       "      <td>-0.194860</td>\n",
       "      <td>-0.284531</td>\n",
       "      <td>-0.489972</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.570316</td>\n",
       "      <td>1.875919</td>\n",
       "      <td>-0.341452</td>\n",
       "      <td>0.287212</td>\n",
       "      <td>0.176271</td>\n",
       "      <td>-0.284531</td>\n",
       "      <td>-0.489972</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.578933</td>\n",
       "      <td>1.092760</td>\n",
       "      <td>3.677903</td>\n",
       "      <td>1.173447</td>\n",
       "      <td>2.681407</td>\n",
       "      <td>2.642731</td>\n",
       "      <td>1.487912</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.045956</td>\n",
       "      <td>-0.594666</td>\n",
       "      <td>-0.341452</td>\n",
       "      <td>-0.779888</td>\n",
       "      <td>-0.937123</td>\n",
       "      <td>-0.284531</td>\n",
       "      <td>-0.819619</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.260735</td>\n",
       "      <td>-0.594666</td>\n",
       "      <td>-0.341452</td>\n",
       "      <td>-0.110690</td>\n",
       "      <td>-0.565991</td>\n",
       "      <td>-0.284531</td>\n",
       "      <td>0.004499</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   shannon_entropy  digit_ratio  sensitive_words  url_length  domain_length  \\\n",
       "0        -1.132160    -0.594666        -0.341452   -0.436245      -0.194860   \n",
       "1         0.570316     1.875919        -0.341452    0.287212       0.176271   \n",
       "2         1.578933     1.092760         3.677903    1.173447       2.681407   \n",
       "3        -2.045956    -0.594666        -0.341452   -0.779888      -0.937123   \n",
       "4        -0.260735    -0.594666        -0.341452   -0.110690      -0.565991   \n",
       "\n",
       "   num_params  special_chars  status  \n",
       "0   -0.284531      -0.489972       0  \n",
       "1   -0.284531      -0.489972       1  \n",
       "2    2.642731       1.487912       1  \n",
       "3   -0.284531      -0.819619       0  \n",
       "4   -0.284531       0.004499       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. Carga del dataset preprocesado (normalizado)\n",
    "\n",
    "DATA_PATH = '../feature engineering/dataset_phishing_preprocessed.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "    print(f\"Dataset cargado desde: {DATA_PATH}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Archivo no encontrado en {DATA_PATH}\")\n",
    "# ── Características seleccionadas ──\n",
    "SELECTED_FEATURES = [\n",
    "    'shannon_entropy', 'digit_ratio', 'sensitive_words',\n",
    "    'url_length', 'domain_length', 'num_params', 'special_chars'\n",
    "]\n",
    "\n",
    "# Verificar columnas\n",
    "missing = [c for c in SELECTED_FEATURES + ['status'] if c not in df.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"Columnas faltantes: {missing}\")\n",
    "\n",
    "df_selected = df[SELECTED_FEATURES + ['status']].copy()\n",
    "\n",
    "print(f\"\\nDimensiones del dataset: {df_selected.shape}\")\n",
    "print(f\"\\nDistribución de clases:\")\n",
    "print(f\"   Legítimas (0): {(df_selected['status'] == 0).sum()}\")\n",
    "print(f\"   Phishing  (1): {(df_selected['status'] == 1).sum()}\")\n",
    "print(f\"\\nPrimeras 5 observaciones:\")\n",
    "df_selected.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f71939",
   "metadata": {},
   "source": [
    "## 2. División del Dataset\n",
    "\n",
    "Se divide en tres conjuntos según las proporciones indicadas:\n",
    "- **Entrenamiento (55%):** ajuste de parámetros del modelo\n",
    "- **Validación (15%):** optimización de hiperparámetros\n",
    "- **Prueba (30%):** evaluación final imparcial\n",
    "\n",
    "Se utiliza estratificación para mantener la proporción de clases y `random_state=42` para reproducibilidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f53f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".......................................................\n",
      "DIVISIÓN DEL DATASET\n",
      ".......................................................\n",
      "  Total:         11430\n",
      "  Entrenamiento: 6286 (55.0%)\n",
      "  Validación:    1715 (15.0%)\n",
      "  Prueba:        3429 (30.0%)\n",
      ".......................................................\n",
      "\n",
      "  Balance de clases por conjunto:\n",
      "    Train: 50.0% phishing / 50.0% legítimas\n",
      "    Val: 50.0% phishing / 50.0% legítimas\n",
      "    Test: 50.0% phishing / 50.0% legítimas\n"
     ]
    }
   ],
   "source": [
    " \n",
    "# 2. División del dataset: 55% train / 15% validation / 30% test\n",
    "\n",
    "X = df_selected[SELECTED_FEATURES]\n",
    "y = df_selected['status']\n",
    "\n",
    "# Paso 1: Separar 70% (train+val) y 30% (test)\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X, y, test_size=0.30, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Paso 2: Del 70%, separar train (55%) y val (15%) → ratio = 15/70 ≈ 0.2143\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, y_train_val, test_size=0.15/0.70, random_state=42, stratify=y_train_val\n",
    ")\n",
    "\n",
    "print(\".\" * 55)\n",
    "print(\"DIVISIÓN DEL DATASET\")\n",
    "print(\".\" * 55)\n",
    "total = len(df_selected)\n",
    "print(f\"  Total:         {total}\")\n",
    "print(f\"  Entrenamiento: {len(X_train)} ({len(X_train)/total*100:.1f}%)\")\n",
    "print(f\"  Validación:    {len(X_val)} ({len(X_val)/total*100:.1f}%)\")\n",
    "print(f\"  Prueba:        {len(X_test)} ({len(X_test)/total*100:.1f}%)\")\n",
    "print(\".\" * 55)\n",
    "print(\"\\n  Balance de clases por conjunto:\")\n",
    "for name, ys in [(\"Train\", y_train), (\"Val\", y_val), (\"Test\", y_test)]:\n",
    "    pct = (ys == 1).sum() / len(ys) * 100\n",
    "    print(f\"    {name}: {pct:.1f}% phishing / {100-pct:.1f}% legítimas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e9f383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivos CSV guardados:\n",
      "   train_dataset.csv\n",
      "   validation_dataset.csv\n",
      "   test_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# Guardar cada split como archivo CSV\n",
    "\n",
    "pd.concat([X_train, y_train], axis=1).to_csv('train_dataset.csv', index=False)\n",
    "pd.concat([X_val, y_val], axis=1).to_csv('validation_dataset.csv', index=False)\n",
    "pd.concat([X_test, y_test], axis=1).to_csv('test_dataset.csv', index=False)\n",
    "\n",
    "print(\"Archivos CSV guardados:\")\n",
    "print(\"   train_dataset.csv\")\n",
    "print(\"   validation_dataset.csv\")\n",
    "print(\"   test_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d85eb10",
   "metadata": {},
   "source": [
    "## 3. Funciones Auxiliares de Evaluación\n",
    "\n",
    "Se definen funciones reutilizables para calcular métricas y generar visualizaciones. En el contexto de detección de phishing:\n",
    "\n",
    "- **TP (Verdadero Positivo):** URL de phishing correctamente detectada → usuario protegido\n",
    "- **TN (Verdadero Negativo):** URL legítima correctamente clasificada → acceso permitido sin problemas\n",
    "- **FP (Falso Positivo):** URL legítima marcada como phishing → bloqueo innecesario, frustración del usuario\n",
    "- **FN (Falso Negativo):** URL de phishing no detectada → usuario expuesto al ataque, riesgo crítico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b667957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Funciones auxiliares definidas\n"
     ]
    }
   ],
   "source": [
    "# 3. Funciones auxiliares de evaluación\n",
    "\n",
    "def evaluate_model(model, X, y_true, set_name, model_name):\n",
    "    \"\"\"\n",
    "    Evalúa un modelo y retorna diccionario con métricas.\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(X)\n",
    "    y_prob = model.predict_proba(X)[:, 1]\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_prob)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    return {\n",
    "        'Modelo': model_name, 'Conjunto': set_name,\n",
    "        'Accuracy':  accuracy_score(y_true, y_pred),\n",
    "        'Precision': precision_score(y_true, y_pred),\n",
    "        'Recall':    recall_score(y_true, y_pred),\n",
    "        'F1-Score':  f1_score(y_true, y_pred),\n",
    "        'AUC':       roc_auc,\n",
    "        'TP': tp, 'TN': tn, 'FP': fp, 'FN': fn,\n",
    "        'fpr': fpr, 'tpr': tpr\n",
    "    }\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(results, ax):\n",
    "    \"\"\"Visualiza la matriz de confusión con contexto de phishing.\"\"\"\n",
    "    cm = np.array([[results['TN'], results['FP']],\n",
    "                   [results['FN'], results['TP']]])\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,\n",
    "                xticklabels=['Legítima (0)', 'Phishing (1)'],\n",
    "                yticklabels=['Legítima (0)', 'Phishing (1)'],\n",
    "                annot_kws={'size': 14})\n",
    "    ax.set_xlabel('Predicción')\n",
    "    ax.set_ylabel('Valor Real')\n",
    "    ax.set_title(f\"Matriz de Confusión\\n{results['Modelo']} — {results['Conjunto']}\", fontsize=12)\n",
    "\n",
    "\n",
    "def plot_roc(results, ax):\n",
    "    \"\"\"Grafica la curva ROC.\"\"\"\n",
    "    ax.plot(results['fpr'], results['tpr'], color='darkorange', lw=2,\n",
    "            label=f\"ROC (AUC = {results['AUC']:.4f})\")\n",
    "    ax.plot([0, 1], [0, 1], 'k--', lw=1.5, label='Aleatorio (AUC = 0.5)')\n",
    "    ax.set_xlim([0, 1]); ax.set_ylim([0, 1.05])\n",
    "    ax.set_xlabel('Tasa de Falsos Positivos (FPR)')\n",
    "    ax.set_ylabel('Tasa de Verdaderos Positivos (TPR)')\n",
    "    ax.set_title(f\"Curva ROC\\n{results['Modelo']} — {results['Conjunto']}\", fontsize=12)\n",
    "    ax.legend(loc='lower right')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "\n",
    "def print_metrics(r):\n",
    "    \"\"\"Imprime métricas con explicación contextual.\"\"\"\n",
    "    print(f\"\\n{'.'*60}\")\n",
    "    print(f\"{r['Modelo']} — Conjunto de {r['Conjunto']}\")\n",
    "    print(f\"{'.'*60}\")\n",
    "    # Accuracy: proporción total de clasificaciones correctas\n",
    "    print(f\"  Accuracy:  {r['Accuracy']:.4f}  — Proporción de predicciones correctas\")\n",
    "    # Precision: de las URLs marcadas como phishing, ¿cuántas realmente lo son?\n",
    "    # Alta precision = pocas falsas alarmas\n",
    "    print(f\"  Precision: {r['Precision']:.4f}  — De las alertas de phishing, ¿cuántas son reales?\")\n",
    "    # Recall: de todas las URLs de phishing reales, ¿cuántas detectamos?\n",
    "    # Alto recall = pocos ataques no detectados\n",
    "    print(f\"  Recall:    {r['Recall']:.4f}  — De todo el phishing real, ¿cuánto detectamos?\")\n",
    "    # F1-Score: balance entre Precision y Recall\n",
    "    print(f\"  F1-Score:  {r['F1-Score']:.4f}  — Balance entre Precision y Recall\")\n",
    "    # AUC: capacidad general de discriminación del modelo\n",
    "    print(f\"  AUC:       {r['AUC']:.4f}  — Capacidad discriminativa general\")\n",
    "    print(f\"{'.'*60}\")\n",
    "    print(f\"  TP={r['TP']} (phishing detectado) | TN={r['TN']} (legítimo OK)\")\n",
    "    print(f\"  FP={r['FP']} (falsa alarma)       | FN={r['FN']} (phishing NO detectado)\")\n",
    "\n",
    "\n",
    "def full_evaluation(model, X, y, set_name, model_name):\n",
    "    \"\"\"Ejecuta evaluación completa: métricas + gráficas.\"\"\"\n",
    "    r = evaluate_model(model, X, y, set_name, model_name)\n",
    "    print_metrics(r)\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    plot_confusion_matrix(r, axes[0])\n",
    "    plot_roc(r, axes[1])\n",
    "    plt.tight_layout(pad=3.0)\n",
    "    plt.show()\n",
    "    return r\n",
    "\n",
    "print(\"Funciones auxiliares definidas\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
